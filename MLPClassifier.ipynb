{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4hIMdfc9qJ4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import os\n",
        "\n",
        "from torchvision import datasets, transforms, models , utils\n",
        "from torch.utils.data import random_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fRcBG4QBnMw"
      },
      "source": [
        "def imshow(img):\n",
        "  ''' function to show image '''\n",
        "  npimg = img.numpy() # convert to numpy objects\n",
        "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hquWHEdVBt35"
      },
      "source": [
        "def to_device(data, device):\n",
        "    \"Move data to the device\"\n",
        "    if isinstance(data,(list,tuple)):\n",
        "        return [to_device(x,device) for x in data]\n",
        "    return data.to(device,non_blocking = True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\" Wrap a dataloader to move data to a device \"\"\"\n",
        "    \n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "    \n",
        "    def __iter__(self):\n",
        "        \"\"\" Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b,self.device)\n",
        "            \n",
        "    def __len__(self):\n",
        "        \"\"\" Number of batches \"\"\"\n",
        "        return len(self.dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lCfTK7bCw_v"
      },
      "source": [
        "# Training class\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEvyWtmxDH14"
      },
      "source": [
        "# Model training and evaluation\n",
        "\n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "  \n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func):\n",
        "    \n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(),lr, momentum = 0.5)\n",
        "    # optimizer = opt_func(model.parameters(),lr)\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            print(loss)\n",
        "\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        print(result['train_loss'])\n",
        "        print(result)\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "        classes_check(val_loader, model)\n",
        "    \n",
        "    return history\n",
        "\n",
        "def classes_check(val_batches, model):\n",
        "    classes = ('cherry', 'strawberry', 'tomato')\n",
        "    # prepare to count predictions for each class\n",
        "    correct_pred = {classname: 0 for classname in classes}\n",
        "    total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "    # again no gradients needed\n",
        "    with torch.no_grad():\n",
        "        for data in val_batches:\n",
        "            images, labels = data\n",
        "            outputs = model(images)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "            # collect the correct predictions for each class\n",
        "            for label, prediction in zip(labels, predictions):\n",
        "                if label == prediction:\n",
        "                    correct_pred[classes[label]] += 1\n",
        "                total_pred[classes[label]] += 1\n",
        "\n",
        "    # print accuracy for each class\n",
        "    for classname, correct_count in correct_pred.items():\n",
        "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "        print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
        "                                                             accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mLx2ZdfCHvB"
      },
      "source": [
        "# MLP model\n",
        "\n",
        "class FruitClassification(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = torch.nn.Linear(270000, 64)\n",
        "        self.layer2 = torch.nn.Linear(64, 12)\n",
        "        self.layer3 = torch.nn.Linear(12, 10)\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        x = self.layer3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek-M4T4PCPqO"
      },
      "source": [
        "def plot_accuracies(history):\n",
        "    \"\"\" Plot the history of accuracies\"\"\"\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');\n",
        "    \n",
        "\n",
        "def plot_losses(history):\n",
        "    \"\"\" Plot the losses in each epoch\"\"\"\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIP6wyV8EuWy"
      },
      "source": [
        "##############################\n",
        "#                            #\n",
        "#     Running Model          #\n",
        "#                            #\n",
        "##############################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfgFHsSmEuyQ",
        "outputId": "bf6f0088-6da0-41c8-c95a-d486b2ebd356"
      },
      "source": [
        "# Import training images from zipped folder in Colab directory\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# !unzip /content/traindata_postselection.zip\n",
        "!unzip /content/traindata.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Archive:  /content/traindata.zip\n",
            "replace traindata/strawberry/strawberry_0943.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoNaQPKRExIK"
      },
      "source": [
        "notebook_path = os.path.abspath(\"MLPClassifier.ipynb\")\n",
        "# data_dir = os.path.join(os.path.dirname(notebook_path), \"traindata_postselection\")\n",
        "data_dir = os.path.join(os.path.dirname(notebook_path), \"traindata\")\n",
        "\n",
        "# dataset = datasets.ImageFolder(data_dir,transform = transforms.Compose([\n",
        "#     transforms.Resize((300, 300)),\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.RandomRotation(),\n",
        "#     transforms.ToTensor(), \n",
        "#     transforms.Normalize(0.5, 0.5, 0.5)\n",
        "# ]))\n",
        "\n",
        "dataset = datasets.ImageFolder(data_dir,transform = transforms.Compose([\n",
        "    transforms.Resize((300, 300)),\n",
        "    transforms.ToTensor()\n",
        "]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4j0ezLq7E4Yo",
        "outputId": "9068be41-a761-4d47-ac2d-e263f048d2f4"
      },
      "source": [
        "batch_size = 30\n",
        "# batch_size = 8\n",
        "val_size = 500\n",
        "train_size = len(dataset) - val_size\n",
        "\n",
        "train_data,val_data = random_split(dataset,[train_size,val_size])\n",
        "print(f\"Length of Train Data : {len(train_data)}\")\n",
        "print(f\"Length of Validation Data : {len(val_data)}\")\n",
        "\n",
        "train_dl = torch.utils.data.DataLoader(train_data, batch_size, shuffle = True)\n",
        "val_dl = torch.utils.data.DataLoader(val_data, batch_size*2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of Train Data : 4000\n",
            "Length of Validation Data : 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83GCTQ6bE76_",
        "outputId": "c8e43481-f5c1-49fe-c5ba-e0ad002796f1"
      },
      "source": [
        "# Load into the device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88Rh0YYlE9W3",
        "outputId": "64a2b899-bff3-4839-806f-fce293ec2455"
      },
      "source": [
        "# Load model to the device\n",
        "model = FruitClassification()\n",
        "to_device(model, device)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FruitClassification(\n",
              "  (layer1): Linear(in_features=270000, out_features=64, bias=True)\n",
              "  (layer2): Linear(in_features=64, out_features=12, bias=True)\n",
              "  (layer3): Linear(in_features=12, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX3YkupDE_Ow",
        "outputId": "fddbf6fb-7875-4f77-c1bc-bb13253c244e"
      },
      "source": [
        "# Initial evaluation of the model\n",
        "evaluate(model, val_dl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'val_acc': 0.018518518656492233, 'val_loss': 2.2710485458374023}"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHEVRSXWFBLf"
      },
      "source": [
        "#set the no. of epochs, optimizer funtion and learning rate\n",
        "num_epochs = 20\n",
        "opt_func = torch.optim.SGD\n",
        "# opt_func = torch.optim.Adam\n",
        "lr = 0.01\n",
        "# lr = 0.001\n",
        "# lr = 0.0001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G87s5ByCFWHT",
        "outputId": "dc2da18b-76c1-4064-a0b0-05defd2e1791"
      },
      "source": [
        "#fitting the model on training data and record the result after each epoch\n",
        "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2797, grad_fn=<NllLossBackward>)\n",
            "tensor(2.2732, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0548, grad_fn=<NllLossBackward>)\n",
            "tensor(2.8060, grad_fn=<NllLossBackward>)\n",
            "tensor(1.7504, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4003, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3254, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2929, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1652, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6605, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0878, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3317, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4519, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5192, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1949, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2782, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2962, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2995, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2463, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2029, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0943, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3514, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1285, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1857, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1872, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1417, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1666, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1705, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1231, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1792, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1463, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1349, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0730, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5166, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1962, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2326, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1702, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1157, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1296, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1410, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1046, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1352, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1469, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0833, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2429, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3800, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1656, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1004, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4133, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1717, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1332, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1827, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1363, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2637, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1361, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1187, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0015, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6107, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0899, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2227, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4042, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1362, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0898, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1839, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1599, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1186, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1432, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1248, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1149, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0524, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1870, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1086, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1556, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1272, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0597, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1357, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1166, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0766, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0401, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0945, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1869, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1802, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1185, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1409, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0896, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1129, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1301, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0893, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0917, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0879, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1999, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1216, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1110, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1350, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2472, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1480, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1199, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1802, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1369, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0223, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2934, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0753, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2156, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1833, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1816, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1195, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0748, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0757, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1477, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1172, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0933, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1127, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0861, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1161, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0265, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2200, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1150, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1898, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0853, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0898, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1607, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0753, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1673, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0824, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1569, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1108, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0626, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0951, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2165, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1458, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0496, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2275, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0246, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2665, grad_fn=<NllLossBackward>)\n",
            "1.217017650604248\n",
            "{'val_loss': 1.177017331123352, 'val_acc': 0.3222222328186035, 'train_loss': 1.217017650604248}\n",
            "Epoch [0], train_loss: 1.2170, val_loss: 1.1770, val_acc: 0.3222\n",
            "Accuracy for class cherry is: 6.5 %\n",
            "Accuracy for class strawberry is: 94.2 %\n",
            "Accuracy for class tomato is: 2.3 %\n",
            "tensor(1.2371, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2000, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3909, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0791, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1441, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0488, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0962, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1580, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0507, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0863, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1040, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0923, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2444, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0396, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2456, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0348, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0133, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0336, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1241, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2433, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0195, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1816, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0574, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0830, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0257, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1267, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0502, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2274, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1886, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1047, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1029, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1579, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1164, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1391, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0458, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1555, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0946, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0270, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0786, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1115, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0676, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0533, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1499, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2475, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1194, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1824, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1538, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1182, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1394, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0160, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0246, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1181, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0099, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2769, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0741, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1316, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1331, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1132, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2160, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0701, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0748, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0992, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0299, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0753, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0615, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0574, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0541, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0343, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0288, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0641, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1615, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0531, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9555, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2018, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1832, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0856, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1868, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0078, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9786, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1773, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1113, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0531, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1655, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9611, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0642, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0815, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0809, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0558, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2844, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0733, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2507, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9717, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2051, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0937, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1098, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1958, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2206, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1094, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0258, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2448, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0672, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0458, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0201, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1770, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1766, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0854, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1738, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0788, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0906, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1033, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1215, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0335, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1011, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1254, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0430, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1402, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0819, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0554, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1825, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2574, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0990, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1590, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1545, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1036, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9599, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1855, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0351, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1434, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0299, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1432, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0809, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1113, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0837, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1393, grad_fn=<NllLossBackward>)\n",
            "1.1096526384353638\n",
            "{'val_loss': 1.1454155445098877, 'val_acc': 0.3722222149372101, 'train_loss': 1.1096526384353638}\n",
            "Epoch [1], train_loss: 1.1097, val_loss: 1.1454, val_acc: 0.3722\n",
            "Accuracy for class cherry is: 92.9 %\n",
            "Accuracy for class strawberry is: 0.0 %\n",
            "Accuracy for class tomato is: 14.7 %\n",
            "tensor(1.1306, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1124, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0393, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1306, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1119, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1746, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0225, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0496, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1065, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0361, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1324, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0554, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0151, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0671, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0139, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0857, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0405, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0983, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0034, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0509, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0534, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1238, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1153, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0939, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0044, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0160, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1111, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1834, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2112, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0659, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2460, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1919, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0417, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0908, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1006, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1341, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0625, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0908, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1771, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0383, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0373, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0914, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0958, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0569, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0880, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1752, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0922, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1212, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0199, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0868, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0676, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0915, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1219, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1447, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0192, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1216, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0519, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0079, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1009, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1216, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1564, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0249, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0987, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0759, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9826, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9910, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2532, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2718, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1859, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1323, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1382, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0638, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0948, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1455, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9981, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0548, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0068, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0500, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0203, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9948, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0414, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0474, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1118, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9306, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1957, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0036, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1872, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0489, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1682, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1244, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0013, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0797, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0113, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0740, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0443, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0826, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0616, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1605, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0666, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0143, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0461, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1025, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0162, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0910, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0638, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1824, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0825, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9646, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9699, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0574, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0055, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9934, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9980, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0271, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0884, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9923, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0326, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0514, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0562, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9593, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2591, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1721, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0527, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0340, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0498, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0593, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1456, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1232, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0299, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0776, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1774, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0882, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0125, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9054, grad_fn=<NllLossBackward>)\n",
            "1.0783988237380981\n",
            "{'val_loss': 1.106065273284912, 'val_acc': 0.4166666567325592, 'train_loss': 1.0783988237380981}\n",
            "Epoch [2], train_loss: 1.0784, val_loss: 1.1061, val_acc: 0.4167\n",
            "Accuracy for class cherry is: 2.4 %\n",
            "Accuracy for class strawberry is: 35.7 %\n",
            "Accuracy for class tomato is: 84.7 %\n",
            "tensor(1.1782, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9989, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0998, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0785, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9406, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0310, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0170, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9859, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1154, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1018, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1221, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0234, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9588, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0939, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2395, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0012, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2268, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0262, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1453, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9986, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1039, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0374, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0409, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0573, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9900, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9604, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1449, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0859, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0243, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0044, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0994, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0404, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9533, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0549, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0019, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0306, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1336, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0588, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9718, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9648, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0617, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9721, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0352, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2565, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1927, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9638, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0255, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0521, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1824, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0243, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1107, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0921, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9682, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1713, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0432, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9804, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9836, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0309, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0071, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0532, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9452, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0618, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0710, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0080, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1461, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9861, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0500, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9985, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0058, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9278, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0754, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9512, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0382, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0917, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1170, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2761, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0477, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0764, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9937, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0112, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0734, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0144, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0839, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0537, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1653, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0618, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1369, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9965, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0520, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0094, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1363, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0082, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1406, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0547, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0842, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1128, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9686, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0772, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9025, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0842, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1478, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0919, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0963, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0983, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0082, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1077, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1383, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9726, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2328, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9814, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1506, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1045, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0313, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0514, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9956, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0414, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9299, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1126, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9110, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1089, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0477, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0051, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0322, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9672, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1477, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1315, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2089, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0751, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0641, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0349, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1356, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0204, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0310, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1001, grad_fn=<NllLossBackward>)\n",
            "1.0579004287719727\n",
            "{'val_loss': 1.0614991188049316, 'val_acc': 0.44814813137054443, 'train_loss': 1.0579004287719727}\n",
            "Epoch [3], train_loss: 1.0579, val_loss: 1.0615, val_acc: 0.4481\n",
            "Accuracy for class cherry is: 44.4 %\n",
            "Accuracy for class strawberry is: 68.2 %\n",
            "Accuracy for class tomato is: 21.5 %\n",
            "tensor(1.1030, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0104, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8904, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0570, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9984, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9245, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0516, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0065, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0151, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0107, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2173, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0293, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0729, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0037, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0735, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9468, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8714, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9988, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8330, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0930, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9804, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2043, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1638, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0550, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0145, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1891, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9257, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0905, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9826, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2679, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9827, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2007, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9950, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8202, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2899, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1152, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0515, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9757, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1513, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9804, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9750, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1272, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9152, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8541, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1561, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0873, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2714, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0511, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0165, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9736, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1114, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0371, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9502, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9421, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9393, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1847, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8663, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9676, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0924, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9180, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0003, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0336, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0325, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0145, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9838, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0339, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0463, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9575, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8980, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1056, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9892, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0210, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0655, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9738, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8837, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1715, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0633, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1102, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9556, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9991, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1557, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0385, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0827, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0091, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0347, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0653, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9476, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0533, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9904, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1910, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1426, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1326, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0034, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0449, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1393, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1916, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0604, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9951, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0567, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9716, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0084, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0706, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0335, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0207, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0800, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0056, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9446, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2320, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1145, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8944, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9903, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0244, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0569, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9816, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9950, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1580, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0332, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9603, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0157, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9444, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2025, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0636, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1360, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0728, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0220, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1388, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0375, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0034, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0805, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9962, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1182, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0200, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0082, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4652, grad_fn=<NllLossBackward>)\n",
            "1.0421953201293945\n",
            "{'val_loss': 1.0580732822418213, 'val_acc': 0.4462963342666626, 'train_loss': 1.0421953201293945}\n",
            "Epoch [4], train_loss: 1.0422, val_loss: 1.0581, val_acc: 0.4463\n",
            "Accuracy for class cherry is: 76.3 %\n",
            "Accuracy for class strawberry is: 21.4 %\n",
            "Accuracy for class tomato is: 31.1 %\n",
            "tensor(0.9772, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0016, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9518, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0317, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0954, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9335, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9648, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2407, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9726, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0359, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9796, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0988, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9274, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9411, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0181, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9702, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8449, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9335, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0504, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9897, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1246, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9630, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2708, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9528, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0815, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1982, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9295, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0609, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8854, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8137, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0997, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9236, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0366, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9501, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9548, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0137, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0008, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0568, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0263, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9834, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0940, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2532, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9346, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9443, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0348, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8926, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0440, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9062, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0617, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1096, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0001, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0245, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0279, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9771, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1031, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9197, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0742, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0498, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0017, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1034, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0077, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9952, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0262, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9062, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9549, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0588, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9904, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2038, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1121, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1047, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1519, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9832, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0645, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9377, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9810, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1053, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9173, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9803, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0351, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1289, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9143, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9731, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9435, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9523, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8921, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3186, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9764, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3889, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0548, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9545, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1358, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0061, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0220, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9812, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9430, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8070, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9159, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0051, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9550, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3083, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0142, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0191, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8499, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9397, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1366, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1136, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1913, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8764, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9721, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1784, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9581, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9935, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0383, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0007, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8774, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9611, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8706, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9681, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1019, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0141, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0266, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1924, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9449, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9634, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0899, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0493, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1645, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0522, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0153, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9827, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0425, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9503, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9553, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8544, grad_fn=<NllLossBackward>)\n",
            "1.0171159505844116\n",
            "{'val_loss': 1.0433026552200317, 'val_acc': 0.47962963581085205, 'train_loss': 1.0171159505844116}\n",
            "Epoch [5], train_loss: 1.0171, val_loss: 1.0433, val_acc: 0.4796\n",
            "Accuracy for class cherry is: 66.9 %\n",
            "Accuracy for class strawberry is: 42.2 %\n",
            "Accuracy for class tomato is: 31.1 %\n",
            "tensor(0.9897, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9745, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0856, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9883, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0335, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3678, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9466, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0593, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0783, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0616, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0745, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0411, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0162, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0253, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9099, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0233, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0729, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0346, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0518, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1459, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1779, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0508, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0415, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9156, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0007, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9385, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1414, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0934, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0306, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8404, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0167, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9614, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9883, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8980, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0498, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0080, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3216, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0926, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1524, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0622, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9017, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8812, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0301, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0004, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9819, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8959, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1091, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0798, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8020, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1278, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8482, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5668, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9604, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9700, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0829, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0227, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9972, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0530, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8972, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9703, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0989, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9736, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0880, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0242, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0976, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9101, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9920, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0044, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9797, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9720, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9163, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8986, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9663, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2063, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0179, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2913, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0375, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1900, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0785, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0481, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9041, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9624, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9241, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0720, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9851, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0389, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9745, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0719, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8533, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9785, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9592, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9574, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0424, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0327, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0088, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9025, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9213, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1934, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9899, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0869, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9594, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0018, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9941, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0253, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9600, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8480, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9816, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0596, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9687, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1029, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9846, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0561, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0652, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0981, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9293, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8197, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8610, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0429, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0879, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7990, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0925, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9395, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2875, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9747, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3808, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0297, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8647, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0097, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0270, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9615, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9773, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0782, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9435, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2430, grad_fn=<NllLossBackward>)\n",
            "1.0227330923080444\n",
            "{'val_loss': 1.0051536560058594, 'val_acc': 0.5074074268341064, 'train_loss': 1.0227330923080444}\n",
            "Epoch [6], train_loss: 1.0227, val_loss: 1.0052, val_acc: 0.5074\n",
            "Accuracy for class cherry is: 46.7 %\n",
            "Accuracy for class strawberry is: 33.1 %\n",
            "Accuracy for class tomato is: 66.7 %\n",
            "tensor(1.0426, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9635, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9745, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1109, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0191, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9511, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0600, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9877, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1109, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9473, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9066, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9808, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0550, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0839, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0612, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0284, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0167, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0342, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0602, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0130, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8356, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9828, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9472, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1419, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9375, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9255, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9841, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8901, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9686, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8202, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1351, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8944, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9793, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9274, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8973, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0063, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8690, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0899, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9542, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0257, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0318, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0035, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1199, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9949, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0322, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2993, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9234, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3581, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0333, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9632, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9354, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0187, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9525, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7578, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2010, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0258, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3727, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2110, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0275, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9502, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9305, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8842, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9901, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6794, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9846, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0153, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2499, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0477, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0046, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0139, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9380, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9494, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0062, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9974, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0014, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7812, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0707, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1607, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0922, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9073, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0831, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0308, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8989, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9055, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0357, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9683, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8961, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9569, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8685, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3245, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1406, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9851, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8707, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0120, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0260, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9025, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8331, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9294, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8498, grad_fn=<NllLossBackward>)\n",
            "tensor(1.5147, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0919, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1635, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8943, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9903, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9042, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0694, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8674, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9950, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0181, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8422, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9507, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9582, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0828, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9951, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9296, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0040, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8798, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9708, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0315, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9845, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9009, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8284, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1739, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9818, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2653, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1473, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1143, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9716, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0488, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9888, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1249, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0900, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9923, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1886, grad_fn=<NllLossBackward>)\n",
            "1.0075253248214722\n",
            "{'val_loss': 1.0480159521102905, 'val_acc': 0.4722222089767456, 'train_loss': 1.0075253248214722}\n",
            "Epoch [7], train_loss: 1.0075, val_loss: 1.0480, val_acc: 0.4722\n",
            "Accuracy for class cherry is: 14.2 %\n",
            "Accuracy for class strawberry is: 52.6 %\n",
            "Accuracy for class tomato is: 72.3 %\n",
            "tensor(0.9941, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9840, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9234, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0559, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9083, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9514, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8367, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9063, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2259, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9326, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9900, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8730, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1689, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9665, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1071, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8292, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0267, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0170, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0143, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0281, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1078, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0000, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0142, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9501, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8327, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9022, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0191, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2124, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0481, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9539, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8626, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1079, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0743, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8925, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1319, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0228, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0678, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2091, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9755, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0241, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0093, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0209, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9258, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0105, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9246, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8330, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9844, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9455, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8925, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9913, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9013, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0537, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9045, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9847, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9715, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0810, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9146, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9785, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1018, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8364, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0444, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8186, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1921, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9524, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0822, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0794, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9828, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9375, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9847, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9114, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9437, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9223, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7767, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8885, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9319, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0393, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8525, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0994, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0638, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9184, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7798, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0057, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1626, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0892, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9284, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9476, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9722, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8294, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9355, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1318, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8640, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8078, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9593, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9290, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9911, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8159, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9872, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9203, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9181, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1389, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2256, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9272, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0558, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0306, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1866, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1690, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8491, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0204, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1121, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1489, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8840, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0199, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9710, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0474, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1789, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8951, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9799, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0079, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8758, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9996, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0300, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8795, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8557, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7515, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9159, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9393, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0595, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7981, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9810, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9939, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7976, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9793, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8843, grad_fn=<NllLossBackward>)\n",
            "0.9806177020072937\n",
            "{'val_loss': 1.0894064903259277, 'val_acc': 0.46481481194496155, 'train_loss': 0.9806177020072937}\n",
            "Epoch [8], train_loss: 0.9806, val_loss: 1.0894, val_acc: 0.4648\n",
            "Accuracy for class cherry is: 35.5 %\n",
            "Accuracy for class strawberry is: 8.4 %\n",
            "Accuracy for class tomato is: 88.1 %\n",
            "tensor(0.9999, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1018, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2335, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9459, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0122, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8455, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8876, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9971, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9578, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8114, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1038, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8318, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1237, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0190, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0705, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0883, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9499, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0618, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9966, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0543, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9188, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9884, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8960, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0052, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8681, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8762, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0585, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7681, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9286, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1060, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9322, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8418, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8960, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0811, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2300, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9216, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9313, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9889, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9602, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8940, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7503, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0717, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0380, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8937, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0710, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1398, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8926, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9268, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9281, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0537, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9983, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9409, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2338, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2242, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9265, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8568, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0573, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9370, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0799, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9337, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8594, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0898, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0497, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9519, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9589, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8199, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8207, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9783, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1031, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9794, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0464, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7993, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2332, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0227, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0117, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8769, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8305, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8730, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4600, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4041, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0475, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2557, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2926, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1740, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0514, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0772, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0609, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1349, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0108, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0258, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9327, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9942, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9737, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8600, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7407, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8605, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0847, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9725, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9543, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0465, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0115, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9242, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9401, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0149, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9846, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8681, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9742, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8594, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9037, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9453, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0097, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0594, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0750, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9745, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9167, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0906, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8814, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8699, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9448, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8691, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9591, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0527, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8964, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1387, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0663, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0994, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0375, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9658, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8822, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9578, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8738, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0426, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8379, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9545, grad_fn=<NllLossBackward>)\n",
            "0.9905838370323181\n",
            "{'val_loss': 1.0955497026443481, 'val_acc': 0.4759259819984436, 'train_loss': 0.9905838370323181}\n",
            "Epoch [9], train_loss: 0.9906, val_loss: 1.0955, val_acc: 0.4759\n",
            "Accuracy for class cherry is: 34.9 %\n",
            "Accuracy for class strawberry is: 7.8 %\n",
            "Accuracy for class tomato is: 90.4 %\n",
            "tensor(1.0478, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9638, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8068, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0841, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9632, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1476, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8756, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8575, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9803, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8905, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9307, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1196, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7974, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9795, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0816, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9520, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9775, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7736, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7776, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9095, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0590, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8999, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9660, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8131, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9363, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8658, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9229, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8276, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9292, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0642, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2763, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9190, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9520, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8542, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9799, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9754, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0405, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9407, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9494, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8719, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0031, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9000, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8705, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1482, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8939, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0586, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9807, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7287, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2324, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0100, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0717, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9108, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9444, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0413, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0102, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0239, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9559, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7443, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8985, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8873, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0148, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2215, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1810, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0751, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8934, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9484, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0248, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9741, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8786, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0429, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9039, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8554, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9527, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0421, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9293, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8672, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9063, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1418, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9399, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0145, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8615, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9748, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8652, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2281, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8820, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0081, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9637, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8626, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9144, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9643, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9370, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8869, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0459, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8605, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8495, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0378, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9461, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7190, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9061, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9021, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8780, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8398, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0010, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7666, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9537, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9076, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9335, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2764, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7684, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2180, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7669, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9849, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8103, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0485, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0393, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9096, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9417, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8732, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8961, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9322, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8939, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9623, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9495, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3350, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8582, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8530, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9010, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8943, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9110, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8486, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8949, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9721, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9829, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8523, grad_fn=<NllLossBackward>)\n",
            "0.9518815279006958\n",
            "{'val_loss': 1.020493745803833, 'val_acc': 0.5018517971038818, 'train_loss': 0.9518815279006958}\n",
            "Epoch [10], train_loss: 0.9519, val_loss: 1.0205, val_acc: 0.5019\n",
            "Accuracy for class cherry is: 27.2 %\n",
            "Accuracy for class strawberry is: 53.9 %\n",
            "Accuracy for class tomato is: 67.8 %\n",
            "tensor(0.9485, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0291, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9509, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7999, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8492, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8731, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8265, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9332, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9783, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3110, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2077, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0251, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1484, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8340, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0352, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9835, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9587, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8866, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9207, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8073, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8274, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0726, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9972, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1006, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8114, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8324, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8949, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0004, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8941, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8483, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0085, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0685, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1764, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9142, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2968, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9390, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8947, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9640, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8833, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0157, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8750, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9500, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8980, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0349, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8206, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8872, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9288, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9208, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0635, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9663, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8585, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8428, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8816, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8371, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7833, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1369, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9829, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9217, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1270, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9342, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9200, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9661, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8674, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9667, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8209, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7769, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9478, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9127, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6820, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0273, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8816, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7946, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8608, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0982, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8109, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7421, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7448, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8951, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9407, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9713, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8633, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9098, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8881, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9144, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1612, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1219, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0035, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0521, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9371, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9894, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9126, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1263, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9713, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8893, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9101, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9892, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1238, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7902, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7941, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8317, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0584, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8762, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0386, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8578, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9700, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9478, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0203, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0411, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1036, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9975, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9737, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1188, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9643, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9147, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0480, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7979, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8335, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9331, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9290, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9838, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7619, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0711, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8684, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8845, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8394, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1034, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8791, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0130, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0416, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8765, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9154, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8987, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8597, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9350, grad_fn=<NllLossBackward>)\n",
            "0.9444897770881653\n",
            "{'val_loss': 0.9800125956535339, 'val_acc': 0.5277777910232544, 'train_loss': 0.9444897770881653}\n",
            "Epoch [11], train_loss: 0.9445, val_loss: 0.9800, val_acc: 0.5278\n",
            "Accuracy for class cherry is: 37.9 %\n",
            "Accuracy for class strawberry is: 39.6 %\n",
            "Accuracy for class tomato is: 78.0 %\n",
            "tensor(0.7693, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8132, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9260, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0584, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1562, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8313, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7651, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9900, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7891, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1102, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7661, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8493, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9578, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0497, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2974, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1644, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3215, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0472, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9143, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9293, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0357, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8743, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9646, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0042, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9122, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9413, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9283, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9240, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8782, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8832, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8527, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9898, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8973, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2252, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9082, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1857, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9380, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8926, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8210, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8662, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9821, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0041, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8174, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7985, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7605, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9492, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1372, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8179, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9731, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0576, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8718, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1847, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0326, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9753, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8575, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9493, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0806, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9158, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9650, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8666, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3160, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9733, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8785, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0857, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8857, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0320, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9515, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8529, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0498, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0402, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7881, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8404, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9639, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9636, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9617, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8760, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9084, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9675, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7699, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0297, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8842, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7743, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9962, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8209, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7940, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8991, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0549, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8778, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9682, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9567, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2539, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0687, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9318, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8776, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8813, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8967, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0443, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8198, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1406, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9404, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9822, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7836, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1856, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9027, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8919, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8881, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9048, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8253, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8349, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8317, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9621, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8567, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7582, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0828, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7671, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9323, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9371, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9117, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7908, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9481, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0381, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1034, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8145, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2278, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1203, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8570, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9925, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9723, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8400, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0783, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9342, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1170, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9785, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8365, grad_fn=<NllLossBackward>)\n",
            "0.9502220749855042\n",
            "{'val_loss': 0.9696391224861145, 'val_acc': 0.5537036657333374, 'train_loss': 0.9502220749855042}\n",
            "Epoch [12], train_loss: 0.9502, val_loss: 0.9696, val_acc: 0.5537\n",
            "Accuracy for class cherry is: 70.4 %\n",
            "Accuracy for class strawberry is: 26.6 %\n",
            "Accuracy for class tomato is: 63.8 %\n",
            "tensor(0.7675, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7614, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6961, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1480, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4422, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7243, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3918, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9519, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2011, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8488, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9669, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9419, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9100, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8384, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7445, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7241, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9691, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9014, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0441, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9404, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9232, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8666, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8768, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9335, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8272, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8133, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7549, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9635, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0362, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9847, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8552, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8649, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8119, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1686, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2453, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8127, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8347, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0211, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9032, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8640, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8452, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9813, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8876, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8624, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7538, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0431, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8966, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9890, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0189, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8842, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9245, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0454, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9116, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9644, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8246, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0826, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8778, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9942, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8532, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7824, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0933, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8757, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8850, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7081, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8972, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9661, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8427, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8316, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9470, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1564, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8818, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7551, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8843, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0152, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9057, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8238, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8918, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9547, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8840, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8410, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8697, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8132, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9616, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7804, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1195, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9032, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8166, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9602, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7561, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8938, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0044, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9581, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0214, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1601, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9936, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2681, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9181, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9469, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8581, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9673, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8732, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9229, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9056, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0072, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9465, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0450, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8203, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9655, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9371, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9099, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9986, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8112, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8811, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9511, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8605, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9082, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8769, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9203, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9818, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9116, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2438, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0134, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9380, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9862, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8149, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8649, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9183, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8784, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7572, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7240, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1736, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7909, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8979, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9116, grad_fn=<NllLossBackward>)\n",
            "0.9257975220680237\n",
            "{'val_loss': 0.96243816614151, 'val_acc': 0.5777778029441833, 'train_loss': 0.9257975220680237}\n",
            "Epoch [13], train_loss: 0.9258, val_loss: 0.9624, val_acc: 0.5778\n",
            "Accuracy for class cherry is: 56.2 %\n",
            "Accuracy for class strawberry is: 44.2 %\n",
            "Accuracy for class tomato is: 69.5 %\n",
            "tensor(1.0366, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1681, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2847, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8023, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0647, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8864, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7399, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8041, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0503, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9753, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8721, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0380, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8475, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8401, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8879, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6588, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8927, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9544, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8793, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8418, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7729, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0257, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0205, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9504, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8344, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0245, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7974, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9744, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9552, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9872, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7451, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8487, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9436, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7332, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8394, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0714, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4130, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0659, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8989, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8879, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8633, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6788, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7508, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0246, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9061, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8255, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8404, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8110, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8349, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9047, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7530, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8003, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8992, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0625, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2399, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9792, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0144, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0654, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0619, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0780, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7288, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0532, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8598, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8917, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8918, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8750, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8391, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8502, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8365, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1085, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8375, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9981, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9890, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7636, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0423, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8841, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9835, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9279, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7457, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6910, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1019, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4393, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9072, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1209, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8863, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8516, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8588, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0124, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8963, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1610, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7737, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8737, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9625, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0370, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0752, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0508, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0095, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9985, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9640, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0015, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8350, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7683, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8885, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9601, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0152, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7763, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8942, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8717, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0656, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7511, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9295, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8588, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3305, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6932, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8351, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9457, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8555, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9095, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9519, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9474, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9812, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0663, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7676, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9913, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8633, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0834, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9565, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9610, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0676, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8761, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7920, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8135, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9290, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2084, grad_fn=<NllLossBackward>)\n",
            "0.932305097579956\n",
            "{'val_loss': 1.348826289176941, 'val_acc': 0.43703705072402954, 'train_loss': 0.932305097579956}\n",
            "Epoch [14], train_loss: 0.9323, val_loss: 1.3488, val_acc: 0.4370\n",
            "Accuracy for class cherry is: 3.6 %\n",
            "Accuracy for class strawberry is: 40.9 %\n",
            "Accuracy for class tomato is: 84.2 %\n",
            "tensor(1.0957, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7601, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9579, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8964, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8777, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9183, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9235, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8586, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8658, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8731, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7528, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8495, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0391, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0040, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8393, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7946, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8565, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6772, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8395, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9233, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8082, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6893, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0399, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8900, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7990, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8307, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8880, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7703, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8228, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7997, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0418, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0472, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7302, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7974, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7835, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2149, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0163, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7265, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7843, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9054, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1633, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8488, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8035, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7611, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9893, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9207, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7431, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8959, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8697, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1623, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6880, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0533, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7584, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8113, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2765, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8046, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1899, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8535, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9257, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8853, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7858, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0143, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9427, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7188, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7850, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2681, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9939, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1556, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1131, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8660, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9746, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0185, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1225, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7975, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9763, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1281, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8118, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0370, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7767, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8332, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0234, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8850, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8644, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9083, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9716, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9354, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0912, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8138, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0031, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8587, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0707, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9959, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1093, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8964, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8163, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0150, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0516, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8875, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0358, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0217, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8809, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8432, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9041, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6003, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0047, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9148, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7893, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9037, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8459, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7965, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9309, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8719, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0609, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1001, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7378, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6400, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7432, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1465, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9784, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1032, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8451, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8824, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0098, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9318, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8245, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8873, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8616, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0186, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9470, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9611, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9686, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9073, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8751, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8812, grad_fn=<NllLossBackward>)\n",
            "0.9131698608398438\n",
            "{'val_loss': 1.1992989778518677, 'val_acc': 0.4185185134410858, 'train_loss': 0.9131698608398438}\n",
            "Epoch [15], train_loss: 0.9132, val_loss: 1.1993, val_acc: 0.4185\n",
            "Accuracy for class cherry is: 97.0 %\n",
            "Accuracy for class strawberry is: 10.4 %\n",
            "Accuracy for class tomato is: 12.4 %\n",
            "tensor(1.1623, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8816, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8850, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8727, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7942, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9353, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8300, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0447, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1981, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8953, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1829, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8378, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8503, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8491, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8585, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8839, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9653, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9900, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0007, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9181, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9538, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9179, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8539, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8499, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9117, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9125, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9653, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7245, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9088, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9168, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9205, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0229, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8914, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8058, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7921, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9540, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7204, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9485, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9287, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0808, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6959, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0019, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9951, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7334, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0951, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9756, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9076, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9576, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7289, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9949, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7468, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6595, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8548, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7122, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8923, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9933, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9977, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3926, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7938, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7495, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7990, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8652, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9051, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8171, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9226, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9146, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8080, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0455, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8112, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8474, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9498, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6900, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7812, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8415, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9136, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0291, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7548, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8080, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7415, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7172, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8784, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9476, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9100, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9981, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9630, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8264, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8835, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0209, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7966, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8418, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7665, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1054, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7845, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9255, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6935, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9145, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0700, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1514, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0461, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8809, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8277, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9604, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7955, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8108, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7643, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9112, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7821, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8575, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7094, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7622, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7215, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7705, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8449, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7864, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0481, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3135, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7613, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8849, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8551, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8428, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0280, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8792, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9366, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8811, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8865, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9166, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8077, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8069, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1046, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8761, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8495, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8000, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7475, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9719, grad_fn=<NllLossBackward>)\n",
            "0.8922675848007202\n",
            "{'val_loss': 1.06425940990448, 'val_acc': 0.5148148536682129, 'train_loss': 0.8922675848007202}\n",
            "Epoch [16], train_loss: 0.8923, val_loss: 1.0643, val_acc: 0.5148\n",
            "Accuracy for class cherry is: 65.7 %\n",
            "Accuracy for class strawberry is: 14.9 %\n",
            "Accuracy for class tomato is: 70.1 %\n",
            "tensor(0.9185, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6519, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9160, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8914, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9207, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7626, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2499, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9805, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0821, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7976, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9617, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9609, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8097, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8811, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7250, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8286, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8923, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1532, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8513, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9430, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7972, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8070, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6975, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9708, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8027, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6786, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7664, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8972, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0868, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7841, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7700, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8463, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7777, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0659, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8292, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0596, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6881, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7167, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8975, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9011, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9855, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8008, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1719, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8433, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0040, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9136, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9420, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9701, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6782, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7280, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6403, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8736, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9357, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6048, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8550, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8035, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8343, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7851, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9773, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6556, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6866, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8064, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8965, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2778, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9289, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8172, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8868, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9231, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7693, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7134, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8334, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6492, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0592, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1188, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8595, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0878, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9987, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8267, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8144, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8469, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7702, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7859, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9414, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1024, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9449, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8038, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0395, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7219, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8831, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9942, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7944, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9975, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7860, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9398, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7295, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9841, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8330, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8921, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0161, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7458, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0380, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9703, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6860, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6943, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1003, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8583, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8686, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0455, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0798, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0573, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9451, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9211, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9166, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9981, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8507, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0868, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9330, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8412, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0678, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9130, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6830, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8439, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8901, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9067, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8064, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0156, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8639, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8556, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8268, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8018, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6713, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9602, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8461, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9847, grad_fn=<NllLossBackward>)\n",
            "0.8832443356513977\n",
            "{'val_loss': 1.1225155591964722, 'val_acc': 0.5, 'train_loss': 0.8832443356513977}\n",
            "Epoch [17], train_loss: 0.8832, val_loss: 1.1225, val_acc: 0.5000\n",
            "Accuracy for class cherry is: 92.3 %\n",
            "Accuracy for class strawberry is: 11.0 %\n",
            "Accuracy for class tomato is: 41.2 %\n",
            "tensor(1.2946, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0197, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9460, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8545, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8904, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8697, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8665, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5066, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7000, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7301, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8892, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0902, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7663, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9570, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1635, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7244, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7750, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8262, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6357, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7982, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7124, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8747, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0315, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8032, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9076, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1574, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1535, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0031, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8728, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0124, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9766, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9279, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7742, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7735, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8526, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9057, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9285, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8886, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7791, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8793, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0242, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8792, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8130, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8036, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8780, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9362, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9929, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7089, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7784, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7407, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9182, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6343, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1076, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7639, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8040, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9678, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8998, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8053, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9960, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7126, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7323, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6187, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7423, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7619, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7961, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8451, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8561, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8349, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8652, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3561, grad_fn=<NllLossBackward>)\n",
            "tensor(2.1199, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0032, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9373, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9080, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9137, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9324, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7907, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7705, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7055, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0171, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9267, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9420, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7708, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7639, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0162, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8372, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7872, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0167, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8704, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7553, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8214, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8219, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6930, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8469, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8163, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0697, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0043, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9258, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2567, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9576, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9106, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9462, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8968, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7426, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7822, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8253, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8159, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7881, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3996, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8755, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8656, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8355, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0707, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7294, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9989, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9118, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7247, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7041, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9317, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7223, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7832, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8362, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0216, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7417, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8657, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7933, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6705, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9314, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7043, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7163, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8814, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7967, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8088, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0164, grad_fn=<NllLossBackward>)\n",
            "0.8890650868415833\n",
            "{'val_loss': 1.166530966758728, 'val_acc': 0.46851852536201477, 'train_loss': 0.8890650868415833}\n",
            "Epoch [18], train_loss: 0.8891, val_loss: 1.1665, val_acc: 0.4685\n",
            "Accuracy for class cherry is: 43.8 %\n",
            "Accuracy for class strawberry is: 79.9 %\n",
            "Accuracy for class tomato is: 20.3 %\n",
            "tensor(0.9703, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7717, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8852, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8543, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7818, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1230, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9126, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7674, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5951, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6564, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8158, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0172, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9225, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6422, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9079, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7631, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6439, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9955, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9814, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7464, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8290, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8984, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7765, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8486, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0261, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9151, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9285, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7620, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6397, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7783, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7583, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6800, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8861, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0144, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7193, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9056, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1674, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7184, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8697, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7582, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8562, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6499, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0934, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9722, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8416, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0541, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7352, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8425, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6354, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9919, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8105, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6793, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9508, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8784, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7583, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7347, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8641, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9787, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6739, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8959, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0434, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8614, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9555, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8455, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7417, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6751, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8992, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8234, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7003, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0298, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8636, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0427, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9254, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8073, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9295, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7621, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7541, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2222, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9214, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1681, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0211, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0179, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8791, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0130, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8102, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7725, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7065, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9013, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5722, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9227, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9819, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6769, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9228, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7429, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7875, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4179, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1888, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9221, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8676, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8077, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9740, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0797, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8926, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1097, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1301, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8150, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8582, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0465, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8299, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9486, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7244, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8357, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8121, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6322, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7620, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8234, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7695, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6470, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8199, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0954, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9795, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8589, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7418, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0479, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1997, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7306, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8897, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7257, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8823, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0736, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8368, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7591, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6664, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5057, grad_fn=<NllLossBackward>)\n",
            "0.8652130365371704\n",
            "{'val_loss': 1.0135083198547363, 'val_acc': 0.5481482148170471, 'train_loss': 0.8652130365371704}\n",
            "Epoch [19], train_loss: 0.8652, val_loss: 1.0135, val_acc: 0.5481\n",
            "Accuracy for class cherry is: 71.0 %\n",
            "Accuracy for class strawberry is: 44.8 %\n",
            "Accuracy for class tomato is: 46.9 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "yxmVsgfkFRqN",
        "outputId": "abf3c409-d4c7-4fbb-fb9b-8be5d8e31d6e"
      },
      "source": [
        "plot_accuracies(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "ENkR-rKeFSg7",
        "outputId": "80033b1a-5112-4860-c600-76583438f8c4"
      },
      "source": [
        "plot_losses(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}